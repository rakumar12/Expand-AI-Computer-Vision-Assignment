# -*- coding: utf-8 -*-
"""Expand AI Computer Vision Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/194ohzLUI081NScL-7XqoWhWE7l5s6THy
"""

from google.colab import drive
drive.mount('/content/drive')

!nvidia-smi

!pip install torchmetrics

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import os
import shutil
import random
import torch
import torchvision
import numpy as np
from PIL import Image
from matplotlib import pyplot as plt
from torchmetrics import ConfusionMatrix
from grad import GradCAM
from utils import deprocess_image
torch.manual_seed(0)

import os
import shutil
import random

classes_list = ['NORMAL', 'PNEUMONIA', 'COVID']
root_path = '/content/drive/MyDrive/DATA/diseases/'
source_file_list = os.listdir(root_path) 

test_ratio = 0.2 

if not os.path.isdir(os.path.join(root_path, 'train')):
    os.mkdir(os.path.join(root_path, 'train'))

if not os.path.isdir(os.path.join(root_path, 'test')):
    os.mkdir(os.path.join(root_path, 'test'))

for c in classes_list:
    if not os.path.exists(root_path +'/train'+'/'+ c):
      os.mkdir(os.path.join(root_path, 'train', c))
    if not os.path.exists(root_path +'/test'+'/'+ c):
      os.mkdir(os.path.join(root_path, 'test', c))

for c in classes_list:
    images = [x for x in source_file_list if x.startswith(c.upper()) and x.lower().endswith('png')]
    print(images)
    n_test = int(len(images) * test_ratio)
    test_images = random.sample(images, n_test)
    for image in images:
        source_path = os.path.join(root_path, image)
        if image in test_images:
            target_path = os.path.join(root_path, 'test', c, image)
        else:
            target_path = os.path.join(root_path, 'train', c, image)
        shutil.move(source_path, target_path)

class Custom_Xray_Dataset(torch.utils.data.Dataset):
    def __init__(self, type ,image_dirs, transform):
        def get_images(class_name):
            images = [x for x in os.listdir(image_dirs[class_name]) if x[-3:].lower().endswith('png')]
            print(f'Found {type} {len(images)} {class_name} examples')
            return images
        
        self.images = {}
        self.classes_list =  ['NORMAL', 'PNEUMONIA', 'COVID']
        
        for class_name in self.classes_list:
            self.images[class_name] = get_images(class_name)
            
        self.image_dirs = image_dirs
        self.transform = transform
        
    
    def __len__(self):
        return sum([len(self.images[class_name]) for class_name in self.classes_list])
    
    
    def __getitem__(self, index):
        class_name = random.choice(self.classes_list)
        index = index % len(self.images[class_name])
        image_name = self.images[class_name][index]
        image_path = os.path.join(self.image_dirs[class_name], image_name)
        img = Image.open(image_path).convert('RGB')
        data = np.asarray(img)
        hist,bins = np.histogram(data.flatten(),256,[0,256])
        cdf = hist.cumsum()
        cdf_normalized = cdf * hist.max()/ cdf.max()
        cdf_m = np.ma.masked_equal(cdf,0)
        cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())
        cdf = np.ma.filled(cdf_m,0).astype('uint8')
        image = Image.fromarray(cdf[img])
        
        return self.transform(image), self.classes_list.index(class_name)

train_transform = torchvision.transforms.Compose([
    torchvision.transforms.Resize(size=(224, 224)),
    torchvision.transforms.RandomHorizontalFlip(),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

test_transform = torchvision.transforms.Compose([
    torchvision.transforms.Resize(size=(224, 224)),
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

def dict_dataset(path):
  data_set = {}
  soure_file_list = ['NORMAL', 'PNEUMONIA', 'COVID']
  for source_file in soure_file_list:
    data_set[source_file] = str(path+'/'+ source_file)
  print('Created........',data_set)  
  return data_set  

train_dataset = Custom_Xray_Dataset('train',dict_dataset('/content/drive/MyDrive/DATA/diseases/train'), train_transform)
test_dataset  = Custom_Xray_Dataset('test',dict_dataset('/content/drive/MyDrive/DATA/diseases/test'), test_transform)

batch_size = 6

train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)

print('Number of training batches', len(train_dl))
print('Number of test batches', len(test_dl))

class_names =  ['NORMAL', 'PNEUMONIA', 'COVID']
dist = {}
quant = {}
        
for class_name in class_names:
    quant[class_name] = [x for x in os.listdir(dict_dataset('/content/drive/MyDrive/DATA/diseases/train')[class_name]) if x[-3:].lower().endswith('png')]
    dist[class_name.replace('_', ' ').capitalize()] = len(quant[class_name])

courses = list(dist.keys())
values = list(dist.values())
  
fig = plt.figure(figsize=(10, 5))
plt.barh(courses, values, color='tab:red')

plt.title("Distribution of classes")
plt.xlabel("Quantity")
plt.ylabel("Labels")
plt.show()

class_names = train_dataset.classes_list

def visualization(images, labels, preds):
    plt.figure(figsize=(20,10))
    for i, image in enumerate(images):
        plt.subplot(1, 6, i + 1, xticks=[], yticks=[])
        image = image.numpy().transpose((1, 2, 0))
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        image = image * std + mean
        image = np.clip(image, 0., 1.)
        plt.imshow(image)
        col = 'green'
        if preds[i] != labels[i]:
            col = 'red'
        plt.xlabel('Actual :' f'{class_names[int(labels[i].numpy())]}',color='green')
        plt.text(9, 20, 'Pred :'f'{class_names[int(preds[i].numpy())]}',fontsize = 15, color='white', bbox={
        'facecolor': col, 'alpha': 0.5, 'pad': 10})    
        # plt.ylabel(f'{class_names[int(preds[i].numpy())]}', color=col)
    plt.tight_layout()
    plt.show()

images, labels = next(iter(train_dl))
visualization(images, labels, labels)

images, labels = next(iter(test_dl))
visualization(images, labels, labels)

model = torchvision.models.resnet18(pretrained=True)
print(model)

model.fc = torch.nn.Linear(in_features=512, out_features=3)
loss_fn = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)

model.cuda().eval()

def visualization_preds():
    model.cuda().eval()
    images, labels = next(iter(test_dl))
    outputs = model(images.cuda())
    _, preds = torch.max(outputs, 1)
    visualization(images.cpu(), labels.cpu(), preds.cpu())



visualization_preds()

def train(epochs):
    print('Starting training..')
    for e in range(0, epochs):
        print('='*20)
        print(f'Starting epoch {e + 1}/{epochs}')
        print('='*20)

        train_loss = 0.
        val_loss = 0.

        model.train() 

        for train_step, (images, labels) in enumerate(train_dl):
            optimizer.zero_grad()
            outputs = model(images.cuda())
            loss = loss_fn(outputs, labels.cuda())
            loss.backward()
            optimizer.step()
            train_loss += loss.item()
            if train_step % 20 == 0:
                print('Evaluating at step', train_step)

                accuracy = 0

                model.eval() 

                for val_step, (images, labels) in enumerate(test_dl):
                    outputs = model(images.cuda())
                    loss = loss_fn(outputs, labels.cuda())
                    val_loss += loss.item()

                    _, preds = torch.max(outputs, 1)
                    accuracy += sum((preds == labels.cuda()).cpu().numpy())

                val_loss /= (val_step + 1)
                accuracy = accuracy/len(test_dataset)
                print(f'Validation Loss: {val_loss:.4f}, Accuracy: {accuracy:.4f}')

                visualization_preds()

                model.train()

                if accuracy >= 0.98:
                    print('Performance condition satisfied, stopping..')
                    return

        train_loss /= (train_step + 1)

        print(f'Training Loss: {train_loss:.4f}')
    print('Training complete..')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# train(epochs=1)

visualization_preds()

torch.save(model.state_dict(),'expand_ai_covid.pth')

s = torch.jit.script(model)
torch.jit.save(s,'expand_ai_covid.pt')

model = torch.load('expand_ai_covid.pt')

classes =('NORMAL', 'PNEUMONIA', 'COVID')
test_pred_labels = []
test_true_labels = []
train_pred_labels = []
train_true_labels = []
ps_list = []
ps_list_train = []
running_correct = 0.0
running_total = 0.0
running_correct_train = 0.0
running_total_train = 0.0
accuracy_test=0.0
accuracy_train=0.0

import torch.nn.functional as F

def data_extraction(pred_label,true_label,ps_label,dataset,correct,total,accuracy):
    with torch.no_grad():
        for images, labels in dataset:
            model.cuda().eval()
            output = model(images.cuda())
            ps = F.softmax(output, dim=1)
            output = (torch.max(torch.exp(output.cpu()), 1)[1]).numpy()
            pred_label.extend(output)
            labels = labels.numpy()
            true_label.extend(labels)
            #ps = ps.data.cpu().numpy().squeeze()
            #ps_label.extend(np.max(ps))
            total += len(labels)
            correct += (output == labels).sum().item()
        accuracy = correct/total
        return pred_label,true_label,ps_label,dataset,correct,total,accuracy

one=data_extraction(test_pred_labels,test_true_labels,ps_list,test_dl,running_correct,running_total,accuracy_test)
print(one[1])
print(one[0])
target_test = torch.tensor(one[1])
preds_test = torch.tensor(one[0])
confmat = ConfusionMatrix(task='multiclass', num_classes=3)
mat_tensor = confmat(preds_test, target_test)
print(mat_tensor)

two=data_extraction(train_pred_labels,train_true_labels,ps_list_train,train_dl,running_correct_train,running_total_train,accuracy_train)

target_train = torch.tensor(two[1])
preds_train = torch.tensor(two[0])
confmat2 = ConfusionMatrix(task='multiclass', num_classes=3)
mat_tensor2 = confmat2(preds_train, target_train)

print(mat_tensor2)

print("Total Correct Images: {}, Total Test Images: {}".format(int(one[4]), int(one[5])))
print("Test Accuracy: ", one[6])

print("Total Correct Images: {}, Total Train Images: {}".format(int(two[4]), int(two[5])))
print("Test Accuracy: ", two[6])

import seaborn as sns

def confutio(mat_tensor,name):
    conf_mat = mat_tensor.numpy()
    group_names = ['True Pos Normal','False Neg','False Neg','False Neg',
                   'False Neg','True Pos Lung','False Neg','False Neg',
                   'False Neg','False Neg','True Pos Pneumonia','False Neg',
                   'False Neg','False Neg','False Neg','True Pos COVID']
    group_counts = ["{0:0.0f}".format(value) for value in
                    conf_mat.flatten()]
    print(group_counts)
    group_percentages = ["{0:.2%}".format(value) for value in
                         conf_mat.flatten()/np.sum(conf_mat)]
    labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in
              zip(group_names,group_counts,group_percentages)]
    labels = np.asarray(labels).reshape(3,3)
    fig, ax = plt.subplots(figsize=(10,10))
    ax=sns.heatmap(conf_mat, annot=labels, fmt='',ax=ax)
    ax.set_title(label=name+' Confussion Matrix')
    ax.plot
    fig.savefig(name+'_confussion.png')

confutio(mat_tensor,'Test')

confutio(mat_tensor2,'Train')

# Commented out IPython magic to ensure Python compatibility.
import sklearn.metrics as metrics
print("Classification report for test set:\n%s\n"
#       % (metrics.classification_report(one[1], one[0],target_names=['NORMAL', 'PNEUMONIA', 'COVID'])))

print("Classification report for train set:\n%s\n"
#       % (metrics.classification_report(two[1], two[0],target_names=['NORMAL', 'PNEUMONIA', 'COVID'])))